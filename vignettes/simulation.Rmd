---
title: "Simulation Study"
output:
  rmarkdown::html_vignette:
    toc: true
    fig_caption: true
    self_contained: yes
fontsize: 11pt
documentclass: article
bibliography: references.bib
csl: reference-style.csl
vignette: >
  %\VignetteIndexEntry{Simulation Study}
  %\VignetteEngine{knitr::rmarkdown_notangle}
---

```{r, include = FALSE}
h <- 3.5
w <- 3.5
is_check <- ("CheckExEnv" %in% search()) || any(c("_R_CHECK_TIMINGS_",
             "_R_CHECK_LICENSE_") %in% names(Sys.getenv()))
knitr::opts_chunk$set(fig.align = "center", eval = !is_check)
```

```{r, include = FALSE}
devtools::load_all()
```

```{r, include = FALSE}
h <- 3.5
w <- 3.5
is_check <- ("CheckExEnv" %in% search()) || any(c("_R_CHECK_TIMINGS_",
             "_R_CHECK_LICENSE_") %in% names(Sys.getenv()))
knitr::opts_chunk$set(fig.align = "center", eval = !is_check)
```

## Introduction

The resources available for conservation are limited. To ensure that conservation resources are allocated cost-effectively, conservation plans (termed prioritizations) can be developed -- using a combination of economic, biodiversity, and land-use data -- to prioritize a set of sites for conservation management (e.g. protected area establishment). However, existing data on biodiversity patterns is incomplete. As a consequence, spatial prioritizations can potentially be improved by collecting additional data (e.g. surveying sites to refine estimates of which species are present inside them). However, this is complicated by the fact that surveying sites consumes limited resources that also need to be used for conservation management. Thus decision makers need to strategically prioritize sites for surveys that will substantially improve spatial prioritisations---this is not a trivial task.

The _surveyvoi_ package is decision support tool for prioritizing sites for surveys based on their potential to improve spatial prioritizations for managing biodiversity. Given a set of sites that could potentially be acquired for conservation management -- wherein some sites have previously been surveyed and other sites have not -- this package aims to identify which sites should be surveyed because doing so could lead to vastly superior conservation management plans (i.e. the management _decision_). Methods are provided to calculate the _expected value of the decision given current information_, and the _expected value of the decision given a survey scheme_ (using exact methods for small problems, and approximation methods for large problems). Furthermore, by examining survey schemes, optimal survey schemes can be identified. In this vignette, we will use a simulated dataset to explore these methods.

## Setup

Let's start by setting up our R session. Here we will load some R packages and pre-set the random number generators for reproducibility.

```{r, message = FALSE, warning = FALSE}
# load packages
library(tidyr)
library(dplyr)
library(surveyvoi)
library(ggplot2)
library(gridExtra)
library(viridis)
library(tibble)
library(RandomFields)

# set RNG seeds for reproducibility
set.seed(505)
RFoptions(seed = 505)

# set default table printing options
options(pillar.sigfig = 6)
```

## Simulate data

Let's simulate some data. To keep things simple, we will simulate data for 30 sites and one conservation feature (e.g. species). Of the 30 sites in total, we will simulate survey data for 20 sites---meaning that 10 of the sites will not have survey data. We will also simulate two spatially auto-correlated variables to characterise the environmental conditions within the sites. Although the simulation code (i.e. `simulate_site_data`) can output the probability that features are expected to inhabit the sites, we will disable this option to make our simulation study more realistic and instead predict these probabilities using statistical models.

```{r}
# simulate site data
site_data <- simulate_site_data(
  n_sites = 30, n_features = 1, proportion_of_sites_missing_data = 10 / 30,
  n_env_vars = 2, max_number_surveys_per_site = 1, output_probabilities = FALSE)

# print site data
print(site_data)

# plot the spatial location of the sites
ggplot(site_data) +
  geom_sf() +
  ggtitle("sites")
```

The `site_data` object is a spatially explicit dataset (i.e. `sf` object) that contains information on the site locations and additional information for each site too. Here, each row corresponds to a different site and each column contains different information about the sites. The `f1` column contains the results from previous surveys, where ones indicate that the feature was previously detected at a site, zeros indicate that the feature has not previously been detected at a site, and missing (`NA`) values mean that a site has not yet been surveyed. The `survey_cost` column contains the cost for surveying each site, and the `management_cost` column contains the cost for managing each site for conservation. The `e1` and `e2` columns contain environmental conditions (e.g. temperature, precipitation). To help understand the simulated data, let's create some visualizations.

```{r, fig.height = h, fig.width = w}
# plot site occupancy data from previous surveys
site_data %>%
  mutate(f1 = as.character(f1)) %>%
  ggplot() +
  geom_sf(aes(color = f1)) +
    scale_color_manual(values = c("1" = "red", "0" = "black"),
                       na.value = "blue") +
    labs(title = "presence/absence data")
```

```{r, fig.height = h, fig.width = w * 1.8}
# plot site cost data
# note that survey and management costs are on different scales
p1 <- ggplot(site_data) +
      geom_sf(aes(color = survey_cost)) +
      scale_color_viridis() +
      labs(title = "survey cost") +
      theme(legend.title = element_blank())
p2 <- ggplot(site_data) +
      geom_sf(aes(color = management_cost)) +
      scale_color_viridis() +
      labs(title = "management cost") +
      theme(legend.title = element_blank())
grid.arrange(p1, p2, nrow = 1)
```

```{r, fig.height = h, fig.width = w * 1.5}
# plot site environmental data
site_data %>%
  select(starts_with("e")) %>%
  gather(var, value, -geometry) %>%
  ggplot() +
  geom_sf(aes(color = value)) +
    facet_wrap(~ var) +
    scale_color_viridis() +
    labs(title = "environmental conditions")
```

After simulating data for the sites, we will simulate data for the conservation feature.

```{r}
# simulate feature data
feature_data <- simulate_feature_data(
  n_features = 1, proportion_of_survey_features = 1)

# manually set target
feature_data$target <- 10

# print feature data
print(feature_data)
```

The `feature_data` object is a table (i.e. `tibble` object) that contains information on the conservation feature. Here, each row corresponds to a different feature -- and so it only has one row because we only have one feature -- and each column contains different information about the feature(s). The `name` column contains the name of the feature. The `survey` column indicates if the feature will be examined in future surveys. The `target` column specifies the amount of occupied sites for each species that should ideally be represented by the prioritization. Finally, the `sensitivity` and `specificity` columns denote the sensitivity (probability of correctly detecting a presence) and specificity (probability of correctly detecting an absence) of the survey methodology.

## Modelling probability of occupancy

After simulating the data, we need to estimate the probability of the feature occurring in the unsurveyed sites. This is important for calculating the return on investment of surveying sites, because if we can reliably predict the probability of the feature(s) occurring in unsurveyed sites using models then we may not need to survey them. Specifically, we will fit gradient boosted regression trees -- via the [xgboost R package](https://xgboost.readthedocs.io/en/latest/) -- using functions contained in this package. These models are well-suited for modelling species distributions because they can accommodate high order interactions among different predictor variables that are needed to effectively model species' environmental niches.

```{r}
# create list of candidate parameter value for calibration procedure
xgb_parameters <- list(eta = 0.1, lambda = 0.1, objective = "binary:logistic")

# identify suitable parameters for model fitting
# ideally, we would try a larger range of values,
# but we will keep it low to reduce processing time for this example
xgb_results <- fit_occupancy_models(
  site_data, feature_data,
  "f1", "n1", c("e1", "e2"),
  "survey_sensitivity", "survey_specificity",
  xgb_n_folds = 2, xgb_tuning_parameters = xgb_parameters)
```

After fitting the models, we can examine the tuning parameters used to fit the models, extract the modelled probability of occupancy, and evaluate the performance of the models.

```{r}
# print best parameters
print(xgb_results$parameters)

# print model performance (TSS value)
xgb_performance <- xgb_results$performance
print(data.frame(xgb_performance))

# store the model sensitivities and specificities in the feature_data object
feature_data$model_sensitivity <- xgb_performance$test_sensitivity_mean
feature_data$model_specificity <- xgb_performance$test_specificity_mean

# store predicted probabilities values in the site_data object
xgb_predictions <- xgb_results$predictions
print(xgb_predictions)
site_data$p1 <- xgb_predictions$f1

# plot site estimated occupancy probabilities
ggplot(site_data) +
  geom_sf(aes(color = p1)) +
  scale_color_viridis() +
  labs(title = "modelled probabilities")
```

```{r, include = FALSE}
stopifnot(xgb_performance$test_tss_mean > 0)
stopifnot(all(feature_data$model_sensitivity > 0.5))
stopifnot(all(feature_data$model_specificity > 0.5))
```

## Expected value given current information

After simulating and modelling the data, we will now examine the _expected value of the decision given current information_. This value represents the conservation value of the optimal spatial prioritization given current information, whilst accounting for uncertainty in the presence (and absence) of the conservation feature in each site. Specifically, "current information" refers to our existing survey data and our occupancy models. Next, we will set a total budget (i.e. `total_budget`). This total budget represents the total amount of resources available for surveying sites and managing them for conservation. It will be set as 80% of the total site management costs.

```{r}
# calculate total budget for surveying and managing sites
total_budget <- sum(site_data$management_cost) * 0.8

# print total budget
print(total_budget)
```

Given the total budget, we can now calculate the _expected value of the decision given current information_.

```{r}
# expected value of the decision given current information
evd_current <- evdci(
  site_data = site_data,
  feature_data = feature_data,
  site_detection_columns = "f1",
  site_n_surveys_columns = "n1",
  site_probability_columns = "p1",
  site_management_cost_column = "management_cost",
  feature_survey_sensitivity_column = "survey_sensitivity",
  feature_survey_specificity_column = "survey_specificity",
  feature_model_sensitivity_column = "model_sensitivity",
  feature_model_specificity_column = "model_specificity",
  feature_target_column = "target",
  total_budget = total_budget)

# print value
print(evd_current)
```

We can potentially improve the _expected value of the decision given current information_ by learning more about which sites are more likely (and less likely) to contain the conservation feature.

## Survey schemes

Now we will generate some candidate survey schemes to see if we can improve the management decision. To achieve this, we will set a budget for surveying additional sites. Specifically, this survey budget (i.e. `survey_budget`) will be set as 40% of the survey costs for the unsurveyed sites. Note that our total budget must always be greater than or equal to the survey budget.

```{r}
# calculate budget for surveying sites
#   add column to site_data indicating if the sites already have data or not
site_data$surveyed <- site_data$n1 < 0.5

#   add column to site_data containing the additional survey costs,
#   i.e. sites that already have data have a zero cost, and
#   sites that are missing data retain their cost values
site_data <-
  site_data %>%
  mutate(new_survey_cost = if_else(surveyed, 0, survey_cost))

#   calculate total cost of surveying remaining unsurveyed sites
total_cost_of_surveying_remaining_sites <-
  sum(site_data$new_survey_cost)

#   calculate budget for surveying sites
survey_budget <- total_cost_of_surveying_remaining_sites * 0.4

# print budgets
print(survey_budget)
print(total_budget)
```

```{r, include = FALSE}
# check that total_budget >= survey budget
stopifnot(total_budget >= survey_budget)
```

We will generate survey schemes by selecting unsurveyed sites that (i) increase geographic coverage among surveyed sites, (ii) increase coverage of environmental conditions among surveyed sites [i.e. environmental diversity; @r2], (iii) select unsurveyed site with highly uncertain modelled predictions (i.e. modelled probabilities close to 0.5), (iv) increase coverage of sites that have low management costs, and (v) increase coverage of sites with high modelled probabilities of occupancy (i.e. predicted site richness).

```{r}
# (i) generate survey scheme to increase geographic coverage
geo_scheme <- geo_cov_survey_scheme(site_data, "new_survey_cost", survey_budget,
                                    locked_out = "surveyed")

# (ii) generate survey scheme to increase environmental diversity,
# environmental distances are calculated using Euclidean distances here,
# though we might consider something like Mahalanobis distances for a
# real dataset to account for correlations among environmental variables)
env_scheme <- env_div_survey_scheme(site_data, "new_survey_cost", survey_budget,
                                    c("e1", "e2"), locked_out = "surveyed",
                                    method = "euclidean")

# (iii) generate survey scheme using site uncertainty scores
# calculate site uncertainty scores
site_data$uncertainty_score <- relative_site_uncertainty_scores(site_data, "p1")

# generate survey scheme
unc_scheme <- weighted_survey_scheme(site_data, "new_survey_cost",
                                     survey_budget, "uncertainty_score",
                                     locked_out = "surveyed")

# (iv) generate survey scheme using site management cheapness
# (i.e. inverse management cost)
site_data$inv_management_cost <- 1 / site_data$management_cost
cheap_scheme <- weighted_survey_scheme(site_data, "new_survey_cost",
                                       survey_budget, "inv_management_cost",
                                       locked_out = "surveyed")

# (v) generate survey scheme using site richness scores
# calculate site richness scores
site_data$richness_score <- relative_site_richness_scores(site_data, "p1")

# generate survey scheme
rich_scheme <- weighted_survey_scheme(site_data, "new_survey_cost",
                                      survey_budget, "richness_score",
                                      locked_out = "surveyed")
```

```{r, include = FALSE}
assertthat::assert_that(!all(c(env_scheme) == c(geo_scheme)))
```

Let's visualize the different survey schemes.

```{r, fig.height = h * 1.5, fig.width = w * 1.8}
# add schemes to site_data
site_data$geo_scheme <- c(geo_scheme)
site_data$env_scheme <- c(env_scheme)
site_data$unc_scheme <- c(unc_scheme)
site_data$cheap_scheme <- c(cheap_scheme)
site_data$rich_scheme <- c(rich_scheme)

# plot the schemes
site_data %>%
  select(contains("scheme")) %>%
  gather(name, value, -geometry) %>%
  mutate_if(is.logical, as.character) %>%
  mutate(name = factor(name, levels = unique(name))) %>%
  ggplot() +
    geom_sf(aes(color = value)) +
    facet_wrap(~ name, nrow = 2) +
    scale_color_manual(values = c("TRUE" = "red", "FALSE" = "black"))
```

We can see that different approaches yield different survey schemes -- but which survey scheme is the best?

## Expected value of the decision given the candidate survey schemes

Now that we've generated the survey schemes, let's calculate the _expected value of the decision of each survey scheme_.

```{r, fig.height = h, fig.width = w * 2.0}
# create table to store results
evd_survey_schemes <-
  tibble(name = c("geo_scheme", "env_scheme", "unc_scheme", "cheap_scheme",
                  "rich_scheme"))

# expected value of the decision given each survey scheme
evd_survey_schemes$value <- sapply(
  evd_survey_schemes$name, function(x) {
    evdsi(
      site_data = site_data,
      feature_data = feature_data,
      site_detection_columns = "f1",
      site_n_surveys_columns = "n1",
      site_probability_columns = "p1",
      site_env_vars_columns = c("e1", "e2"),
      site_survey_scheme_column = as.character(x),
      site_management_cost_column = "management_cost",
      site_survey_cost_column = "survey_cost",
      feature_survey_column = "survey",
      feature_survey_sensitivity_column = "survey_sensitivity",
      feature_survey_specificity_column = "survey_specificity",
      feature_model_sensitivity_column = "model_sensitivity",
      feature_model_specificity_column = "model_specificity",
      feature_target_column = "target",
      total_budget = total_budget,
      xgb_tuning_parameters = xgb_parameters,
      xgb_n_folds = 2)
})

# print values
print(evd_survey_schemes)
```

We can also calculate how much the information gained from each of the survey schemes is expected to improve the management decision. This quantity is called the _return on investment_ for each survey scheme.

```{r}
# estimate the return on investment for each survey scheme
evd_survey_schemes$roi <-
  evd_survey_schemes$value - evd_current

# print values
print(evd_survey_schemes)

# visualize the return on investment for each survey scheme
# color the best survey scheme in blue
evd_survey_schemes %>%
  mutate(name = factor(name, levels = name),
         is_best = roi == max(roi)) %>%
  ggplot(aes(x = name, y = roi)) +
    geom_col(aes(fill = is_best, color = is_best)) +
    xlab("Survey scheme") +
    ylab("Return on investment") +
    scale_color_manual(values = c("TRUE" = "#3366FF", "FALSE" = "black")) +
    scale_fill_manual(values = c("TRUE" = "#3366FF", "FALSE" = "black")) +
    theme(axis.text.x = element_text(angle = 30, vjust = 0.65),
          legend.position = "none")
```

In this particular simulation, we can see that none of these survey schemes have a positive return on investment. This means that none of these survey schemes would likely lead to a better conservation outcome when considering the funds spent conducting them. So, we would not choose to implement any of these surveys schemes. But what is the best possible -- the optimal -- survey scheme?

## Optimal survey scheme

Now let's identify the optimal survey scheme by directly maximizing the _expected value of the decision given a survey scheme_.

```{r, results = "hide", message = FALSE, warning = FALSE}
# identify optimal survey scheme(s)
# (note here we use approximation methods to reduce computational burden)
time <- system.time({
opt_scheme <- approx_near_optimal_survey_scheme(
    site_data = site_data,
    feature_data = feature_data,
    site_detection_columns = "f1",
    site_n_surveys_columns = "n1",
    site_probability_columns = "p1",
    site_env_vars_columns = c("e1", "e2"),
    site_management_cost_column = "management_cost",
    site_survey_cost_column = "survey_cost",
    feature_survey_column = "survey",
    feature_survey_sensitivity_column = "survey_sensitivity",
    feature_survey_specificity_column = "survey_specificity",
    feature_model_sensitivity_column = "model_sensitivity",
    feature_model_specificity_column = "model_specificity",
    feature_target_column = "target",
    total_budget = total_budget,
    survey_budget = survey_budget,
    xgb_tuning_parameters = xgb_parameters,
    xgb_n_folds = 2,
    method_approx_outcomes = "weighted_without_replacement",
    n_approx_replicates = 1,
    n_approx_outcomes_per_replicate = 10000,
    verbose = TRUE)
})
```

```{r, fig.height = h, fig.width = w * 1.5}
print(time)
# print number of optimal survey schemes
print(nrow(opt_scheme))

# add optimal scheme to site data
site_data$opt_scheme <- c(opt_scheme[1, ])

# plot optimal scheme
site_data %>%
mutate(name = "opt_scheme") %>%
ggplot() +
geom_sf(aes(color = opt_scheme)) +
facet_wrap(~ name, nrow = 1) +
scale_color_manual(values = c("TRUE" = "red", "FALSE" = "black"))
```

We can see that the optimal survey scheme (`opt_scheme`) is different to the previous survey schemes. In particular, the optimal scheme selects fewer sites than the other survey schemes. This result shows that survey schemes need to ensure adequate funds remain for actually achieving conservation objectives.

```{r, fig.height = h, fig.width = w * 1.5}
# calculate return on investment of the optimal scheme
evd_opt <- evdsi(
    site_data = site_data,
    feature_data = feature_data,
    site_detection_columns = "f1",
    site_n_surveys_columns = "n1",
    site_probability_columns = "p1",
    site_env_vars_columns = c("e1", "e2"),
    site_survey_scheme_column = "opt_scheme",
    site_management_cost_column = "management_cost",
    site_survey_cost_column = "survey_cost",
    feature_survey_column = "survey",
    feature_survey_sensitivity_column = "survey_sensitivity",
    feature_survey_specificity_column = "survey_specificity",
    feature_model_sensitivity_column = "model_sensitivity",
    feature_model_specificity_column = "model_specificity",
    feature_target_column = "target",
    total_budget = total_budget,
    xgb_tuning_parameters = xgb_parameters,
    xgb_n_folds = 2)

# calculate value
print(evd_opt)

# append optimal results to results table
evd_survey_schemes <- rbind(
  evd_survey_schemes,
  tibble(name = "opt_scheme", value = evd_opt, roi = evd_opt - evd_current))

# print updated results table
print(evd_survey_schemes)

# visualize return on investment values
# color the best survey scheme in blue
evd_survey_schemes %>%
  mutate(name = factor(name, levels = name),
         is_best = roi == max(roi)) %>%
  ggplot(aes(x = name, y = roi)) +
    geom_col(aes(fill = is_best, color = is_best)) +
    xlab("Survey scheme") +
    ylab("Return on investment") +
    scale_color_manual(values = c("TRUE" = "#3366FF", "FALSE" = "black")) +
    scale_fill_manual(values = c("TRUE" = "#3366FF", "FALSE" = "black")) +
    theme(axis.text.x = element_text(angle = 30, vjust = 0.65),
          legend.position = "none")
```

We can see that the optimal survey scheme has the highest _return on investment_ of all the candidate survey schemes. To understand how sub-optimal the candidate survey schemes actually are, let's compute their relative optimality and visualize them.

```{r, fig.height = h, fig.width = w * 1.5}
# express values in terms of optimality
evd_survey_schemes$optimality <-
  ((max(evd_survey_schemes$roi) - evd_survey_schemes$roi) /
   max(evd_survey_schemes$roi)) * 100

# visualize relative optimality
# zero = optimal, and increasing values indicate greater sub-optimality
evd_survey_schemes %>%
  mutate(name = factor(name, levels = name),
         optimality = abs(optimality),
         is_best = optimality == min(optimality)) %>%
  ggplot(aes(x = name, y = optimality)) +
    geom_point(aes(fill = is_best, color = is_best)) +
    xlab("Survey scheme") +
    ylab("Optimality gap (%)") +
    scale_color_manual(values = c("TRUE" = "#3366FF", "FALSE" = "black")) +
    scale_fill_manual(values = c("TRUE" = "#3366FF", "FALSE" = "black")) +
    theme(axis.text.x = element_text(angle = 30, vjust = 0.65),
          legend.position = "none")
```

We can see that the optimal survey scheme performs much better than all the other survey schemes. This result shows that value of information analyses can potentially improve management decisions by strategically allocating funds to surveys and conservation management.

## References
