% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune_occupancy_models.R
\name{tune_occupancy_models}
\alias{tune_occupancy_models}
\title{Tune occupancy models}
\usage{
tune_occupancy_models(
  site_data,
  site_occupancy_columns,
  site_env_vars_columns,
  parameters,
  n_folds = rep(ifelse(nrow(site_data) > 1000, 10, 5), site_occupancy_columns),
  n_random_search_iterations = 10000,
  early_stopping_rounds = 10,
  site_weight_columns = NULL,
  n_threads = 1,
  verbose = FALSE
)
}
\arguments{
\item{site_data}{\code{\link[sf]{sf}} object with site data.}

\item{site_occupancy_columns}{\code{character} names of \code{numeric}
columns in the
argument to \code{site_data} that contain presence/absence data.
Each column should correspond to a different feature, and contain
binary presence/absence data (zeros or ones) indicating if the
feature was detected in a previous survey or not. If a site has not
been surveyed before, then missing (\code{NA}) values should be used.}

\item{site_env_vars_columns}{\code{character} names of columns in the
argument to \code{site_data} that contain environmental information
for fitting updated occupancy models based on possible survey outcomes.
Each column should correspond to a different environmental variable,
and contain \code{numeric}, \code{factor}, or \code{character} data.
No missing (\code{NA}) values are permitted in these columns.}

\item{parameters}{\code{list} object containing the candidate
parameter values for fitting models. Note this argument must
have a \code{nrounds} element (see example below).
Valid parameters include: \code{"max_depth"}, \code{"eta"},
\code{"nrounds"}, \code{"lambda"}, \code{"subsample"},
\code{"colsample_bytree"}, and \code{"objective"}.
See documentation for the \code{params} argument in
\code{\link[xgboost]{xgb.train}} for more information.}

\item{n_folds}{\code{numeric} number of folds to split the training
data into when fitting models for each feature.
Defaults to 10 if there are more than 1000
rows in the argument \code{site_data}, otherwise defaults to 5.
Note that if the maximum number of minority cases (e.g. 1 presence and
1000 absences) is fewer than the number of folds then one minority case
is sampled per fold.}

\item{n_random_search_iterations}{\code{numeric} number of random search
iterations to use when tuning model parameters. Defaults to 10000.}

\item{early_stopping_rounds}{\code{numeric} model rounds for parameter
tuning. See \code{\link[xgboost]{xgboost}} for more information.
Defaults to 10.}

\item{site_weight_columns}{\code{character} name of columns in
\code{site_data} containing weights for model fitting. These columns must
contain \code{numeric} values. No missing (\code{NA}) values are
permitted. Defaults to \code{NULL} such that all data are given
equal weight when fitting models.}

\item{n_threads}{\code{integer} number of threads to use for fitting models.
Defaults to 1.}

\item{verbose}{\code{logical} indicating if information should be
printed during computations. Defaults to \code{FALSE}.}
}
\value{
\code{list} of \code{list} objects containing the best tuning
  parameters found for each feature.
}
\description{
Identify suitable tuning parameters for fitting models to predict
site occupancy.
}
\details{
A random search method is used to tune the model
 parameters. For a given set of tuning parameters, models are fit
 using k-fold cross-validation (via \code{\link[xgboost]{xgb.cv}}) and the
 binary classification error rate calculated using the data held
 out from each fold is used to quantify the performance. In the event
 that the number of folds for a given feature exceeds the number of sites
 where it was recorded as present or absent, then a randomly selected
 site is added to each fold to ensure that each fold has at least one
 present site and one absent site. The models are
 fit using the \code{early_stopping_rounds} parameter to reduce time-spent
 tuning models. They are also fit using an automatically calibrated
 \code{scale_pos_weight} \code{\link[xgboost]{xgboost}} parameter
 (i.e. number of absence divided by number of presences per feature)
 to account for unbalanced datasets. Note that each feature
 is run with the same seed to ensure reproducibility.
}
\examples{
# set seed
set.seed(100)

# simulate data for 200 sites, 2 features, and 3 environmental variables
 x <- simulate_site_data(200, 2, 0.5, n_env_vars = 3)

# create list of possible tuning parameters for modelling
all_parameters <- list(max_depth = seq(1, 10, 1),
                       eta = seq(0.1, 0.5, 0.1),
                       nrounds = seq(100, 1000, 100),
                       lambda = 10 ^ seq(-1.0, 0.0, 0.25),
                       subsample = seq(0.5, 1.0, 0.1),
                       colsample_bytree = seq(0.4, 1.0, 0.1),
                       objective = "binary:logistic")

# identify suitable tuning parameters for each feature,
# note that we use 10 iterations here so that the example finishes quickly,
# you would probably want something like 1000+
parameters <- tune_occupancy_models(
   x, paste0("f", seq_len(2)), paste0("e", seq_len(3)),
   n_folds = rep(5, 2), n_random_search_iterations = 10,
   early_stopping_rounds = 5, parameters = all_parameters, n_threads = 1)

# print best found parameters for each feature
print(parameters)

}
